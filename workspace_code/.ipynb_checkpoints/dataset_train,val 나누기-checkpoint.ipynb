{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cbe2377",
   "metadata": {},
   "source": [
    "#  3.2 train val 8:2 (9월 7일)\n",
    "- 2차 검증\n",
    "- 이미지 ,라벨(yolo포맷) 필요\n",
    "- 이미지와 라벨이 함께 있는 디렉토리에서 작업함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935e3f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\aiffel\\\\Documents\\\\AirSim\\\\workspace_code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790b0d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd02b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 346\n",
      "val set: 39\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "path_datasets = os.path.expanduser('~')+'\\\\\\Documents\\\\Airsim\\\\datasets\\\\'\n",
    "\n",
    "img_list = sorted(glob.glob(path_datasets + \"*.jpg\"))  #경로.jpg\n",
    "img_name = sorted(os.listdir(path_datasets))           #파일명.jpg\n",
    "\n",
    "label_list = sorted(glob.glob(path_datasets + \"*.txt\"))   ##경로.txt \n",
    "label_name = sorted(os.listdir(path_datasets))            #파일명.txt\n",
    "\n",
    "\n",
    "\n",
    "list_name=[]\n",
    "# 폴더에 jpg과 txt만 존재할 경우(짝으로)\n",
    "for v in img_name:\n",
    "    list_name.append(v.split('.')[0])\n",
    "    #print(name)\n",
    "    \n",
    "#    \n",
    "list_name = list(set(list_name))\n",
    "#print(list_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_names, val_names = train_test_split(list_name, test_size= 0.1, random_state= 199, shuffle=True)\n",
    "\n",
    "\n",
    "print(\"train set: {}\".format(len(train_names)))\n",
    "print(\"val set: {}\".format(len(val_names)))\n",
    "\n",
    "\n",
    "dataset_names = [train_names,val_names,]\n",
    "dataset_kinds = [\"train\\\\\",\"val\\\\\"]\n",
    "\n",
    "def Batch_move_files_yolo_img(dataset_names,dataset_kinds, source_path, destination_path):\n",
    "    for img_list, kind in zip(dataset_names, dataset_kinds):\n",
    "        for img in img_list:\n",
    "            image = img.split('/')[-1] + '.jpg'\n",
    "            \n",
    "            shutil.copy(os.path.join(source_path, image), os.path.join(destination_path + kind, image))\n",
    "    return\n",
    "\n",
    "def Batch_move_files_yolo_label(dataset_names,dataset_kinds, source_path, destination_path):\n",
    "    for txt_list, kind in zip(dataset_names, dataset_kinds):\n",
    "        for txt in txt_list:\n",
    "            #print(file)\n",
    "            txt = txt.split('/')[-1] + '.txt'\n",
    "            \n",
    "            shutil.copy(os.path.join(source_path, txt), os.path.join(destination_path + kind, txt))\n",
    "    return\n",
    "\n",
    "\n",
    "# data path\n",
    "source_dir = os.path.expanduser('~')+'\\\\\\Documents\\\\Airsim\\\\datasets\\\\'\n",
    "\n",
    "# new data path\n",
    "\n",
    "img_dir = os.path.expanduser('~')+'\\\\Documents\\\\Airsim\\\\new\\\\images\\\\'\n",
    "label_dir= os.path.expanduser('~')+'\\\\Documents\\\\Airsim\\\\new\\\\labels\\\\'\n",
    "createFolder(img_dir+dataset_kinds[0])\n",
    "createFolder(img_dir+dataset_kinds[1])\n",
    "createFolder(label_dir+dataset_kinds[0])\n",
    "createFolder(label_dir+dataset_kinds[1])\n",
    "\n",
    "\n",
    "Batch_move_files_yolo_img(dataset_names, dataset_kinds , source_dir, img_dir)\n",
    "\n",
    "Batch_move_files_yolo_label(dataset_names, dataset_kinds , source_dir, label_dir)\n",
    "\n",
    "\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "697575f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp39-cp39-win_amd64.whl (6.9 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\slkaf\\anaconda3\\envs\\yolov5\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\slkaf\\anaconda3\\envs\\yolov5\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.0.1 scikit-learn-0.24.2 threadpoolctl-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da51056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
